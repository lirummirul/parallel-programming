# Parallel Programming
    
### &nbsp;&nbsp;&nbsp;&nbsp;OpenMP предназначен для параллельного программирования на уровне потоков внутри одного процесса. Он позволяет создавать параллельные участки кода с использованием директив компилятора, что облегчает написание многопоточных программ. OpenMP позволяет распараллеливать выполнение циклов, блоков кода и операций внутри одного процесса, используя общую память.
    
### &nbsp;&nbsp;&nbsp;&nbsp;MPI, с другой стороны, является библиотекой для обмена сообщениями между различными процессами, работающими параллельно на разных узлах или ядрах. Он позволяет процессам обмениваться данными через передачу сообщений, даже когда они работают на отдельных компьютерах или узлах кластера. Каждый процесс имеет свое собственное адресное пространство памяти, и MPI обеспечивает механизмы для передачи данных между этими процессами.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;В каждой задачке я могу в комметариях написать "процесс" или "поток", не обращая внимания на термины. 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;В контексте MPI, каждый процесс является отдельным исполняемым потоком, а не отдельным потоком внутри одного процесса.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;То есть, процесс - это отдельный адресный блок, со своей памятью своей собственной копией программы и своим собственным ходом выполнения. Фактически MPI позволяет разделить весь мой код внутри инициализации mpi на процессы. 
А в классическом понимании, например через чистый c++ или через openMP 1 процесс разделяется на несколько потоков, деля одно адресное пространство между собой. Потоки могут выполняться параллельно и совместно использовать общие данные.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;Поэтому в MPI все коментарии правильнее воспринимать через "процессы" 

## Задачи MPI : 

1. Hello world из всех процессов (2 балла) - 1
2. Maксимум массива  (3 балла)  - 2
3. Вычисление числа Пи методом Монте-Карло (3 баллов)  - 2     
4. Среднее арифметическое среди положительных чисел массива (3 баллов)  - 2 
5. Скалярное произведение векторов (3 балла)  - 2
6. Maxmin матрицы (5 балла)   - 3
7. Умножение матрицы на вектор при разделении данных по столбцам (7 баллов - doc7.pdf) - 4
8. Scatter и Gather через Send и Recv(6 баллов)  - 3 
9. Инвертировать массив (6 баллов)  -  3
10. Время передачи для разных Send-oв (6 баллов)  - 3      
11. Циклическая передача данных  (6 баллов)    -  3
12. Передача чисел по кругу  для различных коммуникаторов(+ 3 балла)    
13. Проверка матрицы на симметричность (9 баллов)  
14. Сортировка массива методом чет-нечетной перестановки (13 баллов - doc10.pdf)


## Спецификация задач : 
1. уметь запускать MPI
2. уметь использовать что-то из send, recv,  bcast, reduce
3. метод Монте-Карло для получения Пи, понимается как генерирование случайной последовательности точек из квадрата со сторонами 2 и центром в центре координат. Доля точек попавших в круг с радиусом один умноженная на 4 должна стремиться к числу Пи. Распараллеливание заключается в сбалансированном распределении итераций по процессам.
4. Распределение данных через scatterv. При сборе данных использовать одну операцию но с двумя числами.
5. Распределение данных через scatterv. Есть два массива – надо найти суммы произведений соответствующих координат.
6. Найти седловую точку матрицы. Распределение данных через scatterv. Каждый процесс получает какое-то количество строк матрицы. Находит для каждой строки минимум и выбирает из  них максимальный. Далее из локальных максимумов выбирает глобальный. Проверить совпадают ли maxmin и minmax.
7. На одном процессе заполняется матрица и вектор. Каждый процесс получает несколько столбцов матрицы и столько же элементов вектора. Рассчитывает частичную сумму результирующего вектора.  ci = A i,j * b j   для  j-го столбца. Если столбцов несколько, то cj суммируются. Далее все частичные суммы собираются в результат.
8. На одном процессе есть массив из n чисел. Выводим его. При помощи send, recv раздаем всем процессам по n/size чисел. Свою часть так же копируем в другой массив  размера n/size.  Выводим номер каждого процесса и его часть массива. Далее при помощи send, recv собираем все части массива на каком-либо процессе в новый массив размера n.  Выводим его.
9. Перевернуть массив. Работа процессов должна быть сбалансирована. Можно использовать как и Scatterv, Gatherv, так и  Send, Recv.
10. Программу тестируем на двух процессах. Используем Send, Ssend, Bsend и Rsend  - передаем какой-либо длинный массив или строку второму процессу, и получаем  обратно. Замеряем время потраченные на эти операции.
11. В коммуникаторе передаем сообщение от одного процесса другому с нулевого до size-1. Последний процесс отправляет сообщение нулевому. На каждом процессе сообщение изменяется, если это число, то можно прибавлять или умножать на что-то. 
12. После полного круга из задачи 11, создаем новый коммуникатор (произвольным образом, с меньшим количеством процессов) и повторяем процедуру.
13. Каждый процесс должен получить только нужные ему данные, работа процессов должна быть сбалансирована. 
14. 23 задачи есть в pdf файлах. Рассмотрим алгоритмы на ближайших занятиях.



